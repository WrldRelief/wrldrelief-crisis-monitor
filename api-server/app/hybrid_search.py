"""
üîÑ Hybrid Disaster Search Engine
Í∏∞Î≥∏ API + AI Í≤ÄÏÉâÏùÑ Í≤∞Ìï©Ìïú ÌïòÏù¥Î∏åÎ¶¨Îìú ÏóîÏßÑ (7Ïùº ÏµúÏ†ÅÌôî)
"""

import asyncio
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
import hashlib

from ai_search import DisasterSearchEngine, DisasterInfo
from ai_agent import AISearchAgent
from data_quality import DataQualityEnhancer

logger = logging.getLogger(__name__)

class HybridDisasterEngine:
    """ÌïòÏù¥Î∏åÎ¶¨Îìú Ïû¨Ìï¥ Í≤ÄÏÉâ ÏóîÏßÑ (API + AI)"""
    
    def __init__(self):
        # Í∏∞Ï°¥ API ÏóîÏßÑ (Ïã†Î¢∞Ìï† Ïàò ÏûàÎäî Í∏∞Î≥∏ Îç∞Ïù¥ÌÑ∞)
        self.legacy_engine = DisasterSearchEngine()
        
        # AI ÏóêÏù¥Ï†ÑÌä∏ (ÌíçÎ∂ÄÌïú Î≥¥Í∞ï Îç∞Ïù¥ÌÑ∞)
        self.ai_agent = AISearchAgent()
        
        # ÌíàÏßà Í∞úÏÑ†Í∏∞
        self.quality_enhancer = DataQualityEnhancer()
        
        # 7Ïùº ÏµúÏ†ÅÌôî ÏÑ§Ï†ï
        self.data_range_days = 7
        
    async def get_initial_disasters(self, days: int = 7) -> List[DisasterInfo]:
        """ÌïòÏù¥Î∏åÎ¶¨Îìú Î∞©ÏãùÏúºÎ°ú 7ÏùºÏπò Ïû¨Ìï¥ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        
        logger.info(f"üîÑ Starting hybrid disaster collection for last {days} days...")
        
        try:
            # 1. Í∏∞Î≥∏ Ïã†Î¢∞Ìï† Ïàò ÏûàÎäî ÏÜåÏä§ (API Í∏∞Î∞ò - 80% Îç∞Ïù¥ÌÑ∞)
            logger.info("üìä Collecting reliable API data...")
            reliable_tasks = [
                self.legacy_engine._get_usgs_all_earthquakes(),
                self.legacy_engine._get_reliefweb_disasters(days),
                self.legacy_engine._get_gdacs_alerts(),
                self.legacy_engine._get_week_news_disasters()
            ]
            
            # 2. AI Í≤ÄÏÉâÏúºÎ°ú ÏµúÏã† Ï†ïÎ≥¥ Î≥¥Í∞ï (20% Î≥¥Í∞ï Îç∞Ïù¥ÌÑ∞)
            logger.info("ü§ñ Enhancing with AI search...")
            ai_tasks = [
                self.ai_agent.search_global_disasters_7days()
            ]
            
            # 3. Î≥ëÎ†¨ Ïã§ÌñâÏúºÎ°ú ÏÜçÎèÑ ÏµúÏ†ÅÌôî
            logger.info("‚ö° Running parallel data collection...")
            reliable_results = await asyncio.gather(*reliable_tasks, return_exceptions=True)
            ai_results = await asyncio.gather(*ai_tasks, return_exceptions=True)
            
            # 4. Í≤∞Í≥º Î≥ëÌï©
            all_disasters = []
            
            # API Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
            for result in reliable_results:
                if isinstance(result, list):
                    all_disasters.extend(result)
                    logger.info(f"‚úÖ Added {len(result)} disasters from API source")
                elif isinstance(result, Exception):
                    logger.warning(f"‚ö†Ô∏è API source failed: {result}")
            
            # AI Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä Î∞è Î≥ÄÌôò
            for result in ai_results:
                if isinstance(result, list):
                    # AI Í≤∞Í≥ºÎ•º DisasterInfoÎ°ú Î≥ÄÌôò
                    ai_disasters = [self._convert_ai_to_disaster_info(item) for item in result]
                    all_disasters.extend(ai_disasters)
                    logger.info(f"ü§ñ Added {len(ai_disasters)} disasters from AI search")
                elif isinstance(result, Exception):
                    logger.warning(f"‚ö†Ô∏è AI search failed: {result}")
            
            # 5. 7Ïùº ÌïÑÌÑ∞ÎßÅ
            cutoff_time = datetime.now() - timedelta(days=days)
            cutoff_timestamp = int(cutoff_time.timestamp())
            
            recent_disasters = [
                d for d in all_disasters 
                if d.timestamp >= cutoff_timestamp
            ]
            
            logger.info(f"üìÖ Filtered to {len(recent_disasters)} disasters from last {days} days")
            
            # 6. Ï§ëÎ≥µ Ï†úÍ±∞ Î∞è ÌíàÏßà Í∞úÏÑ†
            unique_disasters = self._deduplicate_disasters(recent_disasters)
            logger.info(f"üîÑ Deduplicated to {len(unique_disasters)} unique disasters")
            
            # 7. Ï¢åÌëú Î∞è ÏúÑÏπò Ï†ïÎ≥¥ Î≥¥Í∞ï
            enhanced_disasters = []
            for disaster in unique_disasters:
                enhanced = await self._enhance_disaster_with_coordinates(disaster)
                enhanced_disasters.append(enhanced)
            
            # 8. ÏãúÍ∞ÑÏàú Ï†ïÎ†¨ (ÏµúÏã†Ïàú)
            sorted_disasters = sorted(enhanced_disasters, key=lambda x: x.timestamp, reverse=True)
            
            logger.info(f"‚úÖ Hybrid collection complete: {len(sorted_disasters)} disasters")
            return sorted_disasters
            
        except Exception as e:
            logger.error(f"‚ùå Hybrid collection failed: {e}")
            return self._get_fallback_data()

    async def search_disasters(self, query: str, max_results: int = 20) -> List[DisasterInfo]:
        """ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâ (API + AI)"""
        
        logger.info(f"üîç Hybrid search for: {query}")
        
        try:
            # API Í≤ÄÏÉâ + AI Í≤ÄÏÉâ Î≥ëÎ†¨ Ïã§Ìñâ
            tasks = [
                self.legacy_engine.search_disasters(query, max_results//2),
                self._ai_search_with_query(query, max_results//2)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Í≤∞Í≥º Î≥ëÌï©
            all_disasters = []
            for result in results:
                if isinstance(result, list):
                    all_disasters.extend(result)
                elif isinstance(result, Exception):
                    logger.warning(f"Search component failed: {result}")
            
            # Ï§ëÎ≥µ Ï†úÍ±∞ Î∞è Ï†ïÎ†¨
            unique_disasters = self._deduplicate_disasters(all_disasters)
            sorted_disasters = sorted(unique_disasters, key=lambda x: x.timestamp, reverse=True)
            
            # Ï¢åÌëú Î≥¥Í∞ï
            enhanced_disasters = []
            for disaster in sorted_disasters[:max_results]:
                enhanced = await self._enhance_disaster_with_coordinates(disaster)
                enhanced_disasters.append(enhanced)
            
            logger.info(f"‚úÖ Hybrid search complete: {len(enhanced_disasters)} results")
            return enhanced_disasters
            
        except Exception as e:
            logger.error(f"‚ùå Hybrid search failed: {e}")
            return self._get_fallback_data()

    async def _ai_search_with_query(self, query: str, max_results: int) -> List[DisasterInfo]:
        """AI Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º DisasterInfoÎ°ú Î≥ÄÌôò"""
        try:
            ai_results = await self.ai_agent.search_with_query(query, max_results)
            return [self._convert_ai_to_disaster_info(item) for item in ai_results]
        except Exception as e:
            logger.warning(f"AI query search failed: {e}")
            return []

    def _convert_ai_to_disaster_info(self, ai_item: Dict) -> DisasterInfo:
        """AI Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º DisasterInfo Í∞ùÏ≤¥Î°ú Î≥ÄÌôò"""
        return DisasterInfo(
            id=ai_item.get('id', f"ai_{hashlib.md5(str(ai_item).encode()).hexdigest()[:8]}"),
            title=ai_item.get('title', 'Unknown Disaster'),
            description=ai_item.get('description', ''),
            location=ai_item.get('location', 'Location TBD'),
            severity=ai_item.get('severity', 'MEDIUM'),
            category=ai_item.get('category', 'OTHER'),
            timestamp=ai_item.get('timestamp', int(datetime.now().timestamp())),
            source=ai_item.get('source', 'AI-Search'),
            confidence=ai_item.get('confidence', 0.8),
            affected_people=ai_item.get('affected_people'),
            damage_estimate=ai_item.get('damage_estimate'),
            coordinates=ai_item.get('coordinates', {"lat": 0.0, "lng": 0.0})
        )

    async def _enhance_disaster_with_coordinates(self, disaster: DisasterInfo) -> DisasterInfo:
        """Ïû¨Ìï¥ Îç∞Ïù¥ÌÑ∞Ïóê Ï†ïÌôïÌïú Ï¢åÌëú Î∞è ÏúÑÏπò Ï†ïÎ≥¥ Î≥¥Í∞ï"""
        
        # Ïù¥ÎØ∏ Ïú†Ìö®Ìïú Ï¢åÌëúÍ∞Ä ÏûàÏúºÎ©¥ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
        if (disaster.coordinates and 
            disaster.coordinates.get('lat', 0) != 0 and 
            disaster.coordinates.get('lng', 0) != 0):
            return disaster
        
        # ÏúÑÏπò Ï†ïÎ≥¥Í∞Ä Î∂ÄÏ°±ÌïòÎ©¥ AIÎ°ú Î≥¥Í∞ï
        if disaster.location in ['Location TBD', 'Unknown Location', '']:
            try:
                # AIÎ°ú ÏúÑÏπò Ï∂îÏ∂ú ÏãúÎèÑ
                enhanced_location = await self._ai_extract_location(disaster)
                if enhanced_location != 'Location TBD':
                    disaster.location = enhanced_location
            except Exception as e:
                logger.warning(f"AI location extraction failed: {e}")
        
        # Ï¢åÌëú Ï†ïÎ≥¥ Î≥¥Í∞ï
        if disaster.location != 'Location TBD':
            try:
                # OpenStreetMapÏúºÎ°ú ÏßÄÏò§ÏΩîÎî©
                coords = await self.ai_agent._geocode_location(disaster.location)
                if coords:
                    disaster.coordinates = coords
                else:
                    # AIÎ°ú Ï¢åÌëú Ï∂îÏ†ï
                    coords = await self.ai_agent._ai_estimate_coordinates(disaster.location)
                    disaster.coordinates = coords
            except Exception as e:
                logger.warning(f"Coordinate enhancement failed for {disaster.location}: {e}")
                disaster.coordinates = {"lat": 0.0, "lng": 0.0}
        
        return disaster

    async def _ai_extract_location(self, disaster: DisasterInfo) -> str:
        """AIÎ°ú Ïû¨Ìï¥ Ï†ïÎ≥¥ÏóêÏÑú Ï†ïÌôïÌïú ÏúÑÏπò Ï∂îÏ∂ú"""
        
        if not self.ai_agent.openai_api_key:
            return disaster.location
        
        prompt = f"""
        Îã§Ïùå Ïû¨Ìï¥ Ï†ïÎ≥¥ÏóêÏÑú Í∞ÄÏû• Ï†ïÌôïÌïòÍ≥† Íµ¨Ï≤¥Ï†ÅÏù∏ ÏúÑÏπòÎ•º Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî:
        
        Ï†úÎ™©: {disaster.title}
        ÏÑ§Î™Ö: {disaster.description}
        ÌòÑÏû¨ ÏúÑÏπò: {disaster.location}
        Ïπ¥ÌÖåÍ≥†Î¶¨: {disaster.category}
        
        ÏöîÍµ¨ÏÇ¨Ìï≠:
        1. ÎèÑÏãú ÏàòÏ§ÄÏùò Íµ¨Ï≤¥Ï†ÅÏù∏ ÏúÑÏπò (Ïòà: "Istanbul, Turkey")
        2. Ïû¨Ìï¥ Îß•ÎùΩÏùÑ Í≥†Î†§Ìïú Ï†ïÌôïÌïú ÏßÄÎ™Ö
        3. "Unknown" ÎòêÎäî "TBD" ÏÇ¨Ïö© Í∏àÏßÄ
        4. Ï∂îÏ†ïÏù¥ÎùºÎèÑ Í∞ÄÏû• Í∞ÄÎä•ÏÑ± ÎÜíÏùÄ Íµ¨Ï≤¥Ï†Å ÏúÑÏπò
        
        ÌòïÏãù: "ÎèÑÏãúÎ™Ö, Íµ≠Í∞ÄÎ™Ö"ÏúºÎ°úÎßå ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.
        """
        
        try:
            import aiohttp
            
            headers = {
                "Authorization": f"Bearer {self.ai_agent.openai_api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 50,
                "temperature": 0.1
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=data
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        location = result['choices'][0]['message']['content'].strip()
                        
                        # Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù
                        if len(location) > 3 and ',' in location:
                            return location
                        
        except Exception as e:
            logger.warning(f"AI location extraction failed: {e}")
        
        return disaster.location

    def _deduplicate_disasters(self, disasters: List[DisasterInfo]) -> List[DisasterInfo]:
        """Ï§ëÎ≥µ Ï†úÍ±∞ (Í∏∞Ï°¥ Î°úÏßÅ Ïû¨ÏÇ¨Ïö© + Í∞úÏÑ†)"""
        seen_keys = set()
        unique_disasters = []
        
        for disaster in disasters:
            # Ï†úÎ™© + ÏúÑÏπò + ÎÇ†Ïßú Í∏∞Î∞ò Ï§ëÎ≥µ ÌÇ§ ÏÉùÏÑ±
            title_normalized = disaster.title.lower().strip()
            location_normalized = disaster.location.lower().strip()
            date_key = datetime.fromtimestamp(disaster.timestamp).strftime('%Y-%m-%d')
            
            duplicate_key = f"{title_normalized}_{location_normalized}_{date_key}"
            duplicate_key = ''.join(c for c in duplicate_key if c.isalnum() or c == '_')
            
            if duplicate_key not in seen_keys and len(title_normalized) > 5:
                seen_keys.add(duplicate_key)
                unique_disasters.append(disaster)
            else:
                logger.debug(f"Duplicate filtered: {disaster.title[:50]}")
        
        return unique_disasters

    def generate_blockchain_data(self, disaster: DisasterInfo) -> Dict:
        """Î∏îÎ°ùÏ≤¥Ïù∏ Ìò∏Ìôò Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± (Ï¢åÌëú Ìè¨Ìï®)"""
        return {
            "id": disaster.id,
            "name": disaster.title,
            "description": disaster.description,
            "location": disaster.location,
            "coordinates": disaster.coordinates or {"lat": 0.0, "lng": 0.0},
            "start_date": disaster.timestamp,
            "end_date": 0,  # ÏßÑÌñâÏ§ë
            "image_url": "",
            "external_source": disaster.source,
            "status": 0,  # ÌôúÏÑ±
            "created_at": int(datetime.now().timestamp()),
            "updated_at": int(datetime.now().timestamp()),
            "created_by": "0x0000000000000000000000000000000000000000",
            "severity": disaster.severity,
            "category": disaster.category,
            "confidence": disaster.confidence,
            "affected_people": disaster.affected_people or 0,
            "damage_estimate": disaster.damage_estimate or "TBD"
        }

    def _get_fallback_data(self) -> List[DisasterInfo]:
        """Ìè¥Î∞± Îç∞Ïù¥ÌÑ∞"""
        return [
            DisasterInfo(
                id="hybrid_fallback_001",
                title="Hybrid System Monitoring Active",
                description="Hybrid disaster monitoring system (API + AI) is active and searching for global events.",
                location="Global",
                severity="LOW",
                category="SYSTEM",
                timestamp=int(datetime.now().timestamp()),
                source="Hybrid-System",
                confidence=1.0,
                affected_people=0,
                damage_estimate="N/A",
                coordinates={"lat": 0.0, "lng": 0.0}
            )
        ]
