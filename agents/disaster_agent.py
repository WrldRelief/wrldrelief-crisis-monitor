"""
ğŸ¤– WRLD Relief Disaster Monitoring uAgent
ASI Alliance í†µí•©ì„ ìœ„í•œ ì¬í•´ ëª¨ë‹ˆí„°ë§ ì—ì´ì „íŠ¸
ê¸°ì¡´ AI ê²€ìƒ‰ ì‹œìŠ¤í…œì„ uAgentë¡œ ë˜í•‘
"""

import asyncio
import logging
import sys
import os
from typing import List, Dict, Any
from datetime import datetime

# uAgents ë¼ì´ë¸ŒëŸ¬ë¦¬
from uagents import Agent, Context, Model
from uagents.setup import fund_agent_if_low

# ê¸°ì¡´ í”„ë¡œì íŠ¸ ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'api-server', 'app'))

try:
    from ai_agent import AISearchAgent
    from ai_search import DisasterInfo
    import json
    from pathlib import Path
except ImportError as e:
    logging.error(f"Failed to import existing modules: {e}")
    logging.error("Make sure you're running from the project root directory")
    sys.exit(1)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ë©”ì‹œì§€ ëª¨ë¸ ì •ì˜
class DisasterQuery(Model):
    """ì¬í•´ ê²€ìƒ‰ ì¿¼ë¦¬ ë©”ì‹œì§€"""
    query: str = "global disasters today"
    max_results: int = 10
    requester: str = "user"

class DisasterResult(Model):
    """ê°œë³„ ì¬í•´ ê²°ê³¼"""
    id: str
    title: str
    description: str
    location: str
    severity: str
    category: str
    timestamp: int
    source: str
    confidence: float
    affected_people: int = 0
    coordinates: Dict[str, float] = {"lat": 0.0, "lng": 0.0}

class DisasterResults(Model):
    """ì¬í•´ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸"""
    disasters: List[DisasterResult]
    total_count: int
    query: str
    searched_at: int
    agent_name: str = "WRLD Relief Disaster Agent"

class AgentStatus(Model):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ì •ë³´"""
    status: str = "online"
    last_search: str = ""
    total_searches: int = 0
    uptime: str = ""

# uAgent ìƒì„± (ë¡œì»¬ ì „ìš©, Almanac ë“±ë¡ ë¹„í™œì„±í™”)
agent = Agent(
    name="wrld_relief_disaster_agent",
    seed="wrld_relief_disaster_monitoring_seed_2025",
    port=8001,
    endpoint=["http://localhost:8001/submit"],
    mailbox=False  # Almanac ë“±ë¡ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë¹„í™œì„±í™”
)

# ê¸€ë¡œë²Œ ë³€ìˆ˜
search_engine = None
search_count = 0
start_time = datetime.now()

@agent.on_event("startup")
async def startup_handler(ctx: Context):
    """ì—ì´ì „íŠ¸ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    global search_engine
    
    logger.info(f"ğŸš€ WRLD Relief Disaster Agent starting...")
    logger.info(f"ğŸ”— Agent address: {agent.address}")
    logger.info(f"ğŸŒ Agent endpoint: {agent._endpoints}")
    
    # AI ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    try:
        search_engine = AISearchAgent()
        logger.info("âœ… AI Search Engine initialized")
    except Exception as e:
        logger.error(f"âŒ Failed to initialize AI Search Engine: {e}")
        search_engine = None
    
    # ì—ì´ì „íŠ¸ ìê¸ˆ í™•ì¸ (í…ŒìŠ¤íŠ¸ë„·ìš©)
    try:
        await fund_agent_if_low(agent.wallet.address())
        logger.info("ğŸ’° Agent funding checked")
    except Exception as e:
        logger.warning(f"âš ï¸ Funding check failed: {e}")
    
    logger.info("âœ… WRLD Relief Disaster Agent ready for disaster monitoring!")

def load_cached_disasters():
    """ìºì‹œëœ ì¬í•´ ë°ì´í„° ë¡œë“œ"""
    try:
        cache_path = Path(__file__).parent.parent / "api-server" / "data" / "disasters_cache.json"
        if cache_path.exists():
            with open(cache_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('disasters', [])
    except Exception as e:
        logger.error(f"Failed to load cached disasters: {e}")
    return []

def search_disasters_by_query(disasters_data: List[Dict], query: str, max_results: int = 10) -> List[Dict]:
    """ì¿¼ë¦¬ì— ë”°ë¼ ì¬í•´ ë°ì´í„° ê²€ìƒ‰"""
    query_lower = query.lower()
    matched_disasters = []
    
    # í‚¤ì›Œë“œ ë§¤ì¹­
    for disaster in disasters_data:
        title = disaster.get('title', '').lower()
        description = disaster.get('description', '').lower()
        location = disaster.get('location', '').lower()
        category = disaster.get('category', '').lower()
        
        # ê²€ìƒ‰ ì ìˆ˜ ê³„ì‚°
        score = 0
        
        # ì¿¼ë¦¬ í‚¤ì›Œë“œë“¤ë¡œ ë¶„í• 
        query_words = query_lower.split()
        
        for word in query_words:
            if word in title:
                score += 3  # ì œëª©ì—ì„œ ë°œê²¬ì‹œ ë†’ì€ ì ìˆ˜
            if word in description:
                score += 2  # ì„¤ëª…ì—ì„œ ë°œê²¬ì‹œ ì¤‘ê°„ ì ìˆ˜
            if word in location:
                score += 2  # ìœ„ì¹˜ì—ì„œ ë°œê²¬ì‹œ ì¤‘ê°„ ì ìˆ˜
            if word in category:
                score += 1  # ì¹´í…Œê³ ë¦¬ì—ì„œ ë°œê²¬ì‹œ ë‚®ì€ ì ìˆ˜
        
        # íŠ¹ë³„ í‚¤ì›Œë“œ ì²˜ë¦¬
        if any(word in ['earthquake', 'seismic', 'ì§€ì§„'] for word in query_words):
            if disaster.get('category') == 'EARTHQUAKE':
                score += 5
        
        if any(word in ['flood', 'flooding', 'í™ìˆ˜'] for word in query_words):
            if disaster.get('category') == 'FLOOD':
                score += 5
                
        if any(word in ['fire', 'wildfire', 'ì‚°ë¶ˆ'] for word in query_words):
            if disaster.get('category') == 'WILDFIRE':
                score += 5
                
        if any(word in ['hurricane', 'typhoon', 'cyclone', 'íƒœí’', 'í—ˆë¦¬ì¼€ì¸'] for word in query_words):
            if disaster.get('category') == 'HURRICANE':
                score += 5
                
        if any(word in ['volcano', 'volcanic', 'í™”ì‚°'] for word in query_words):
            if disaster.get('category') == 'VOLCANO':
                score += 5
                
        if any(word in ['war', 'conflict', 'attack', 'ì „ìŸ', 'ë¶„ìŸ'] for word in query_words):
            if disaster.get('category') == 'OTHER' and any(word in description for word in ['attack', 'killed', 'war', 'conflict']):
                score += 5
        
        # ì§€ì—­ë³„ ê²€ìƒ‰
        if any(word in ['japan', 'japanese', 'ì¼ë³¸'] for word in query_words):
            if 'japan' in location:
                score += 4
                
        if any(word in ['china', 'chinese', 'ì¤‘êµ­'] for word in query_words):
            if 'china' in location:
                score += 4
                
        if any(word in ['usa', 'america', 'united states', 'ë¯¸êµ­'] for word in query_words):
            if any(word in location for word in ['united states', 'usa', 'america']):
                score += 4
        
        if score > 0:
            disaster_copy = disaster.copy()
            disaster_copy['search_score'] = score
            matched_disasters.append(disaster_copy)
    
    # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìµœëŒ€ ê²°ê³¼ ìˆ˜ë§Œí¼ ë°˜í™˜
    matched_disasters.sort(key=lambda x: x.get('search_score', 0), reverse=True)
    return matched_disasters[:max_results]

@agent.on_message(model=DisasterQuery)
async def handle_disaster_query(ctx: Context, sender: str, msg: DisasterQuery):
    """ì¬í•´ ê²€ìƒ‰ ì¿¼ë¦¬ ì²˜ë¦¬ - ì‹¤ì œ ìºì‹œëœ ë°ì´í„° ì‚¬ìš©"""
    global search_count
    search_count += 1
    
    logger.info(f"ğŸ” Received disaster query from {sender}: '{msg.query}'")
    logger.info(f"ğŸ“Š Search count: {search_count}")
    
    try:
        # ìºì‹œëœ ì‹¤ì œ ë°ì´í„° ë¡œë“œ
        cached_disasters = load_cached_disasters()
        logger.info(f"ğŸ“¦ Loaded {len(cached_disasters)} cached disasters")
        
        # ì¿¼ë¦¬ì— ë”°ë¼ ê²€ìƒ‰
        matched_disasters = search_disasters_by_query(
            cached_disasters, 
            msg.query, 
            msg.max_results
        )
        
        # DisasterResult ëª¨ë¸ë¡œ ë³€í™˜
        disaster_results = []
        for disaster in matched_disasters:
            disaster_result = DisasterResult(
                id=disaster.get('id', 'unknown'),
                title=disaster.get('title', 'Unknown Disaster'),
                description=disaster.get('description', ''),
                location=disaster.get('location', 'Unknown Location'),
                severity=disaster.get('severity', 'MEDIUM'),
                category=disaster.get('category', 'OTHER'),
                timestamp=disaster.get('timestamp', int(datetime.now().timestamp())),
                source=disaster.get('source', 'WRLD Relief Cache'),
                confidence=disaster.get('confidence', 0.8),
                affected_people=disaster.get('affected_people', 0) or 0,
                coordinates=disaster.get('coordinates', {"lat": 0.0, "lng": 0.0})
            )
            disaster_results.append(disaster_result)
        
        # ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
        results = DisasterResults(
            disasters=disaster_results,
            total_count=len(disaster_results),
            query=msg.query,
            searched_at=int(datetime.now().timestamp()),
            agent_name="WRLD Relief Disaster Agent"
        )
        
        logger.info(f"âœ… Found {len(disaster_results)} disasters for query: '{msg.query}'")
        if disaster_results:
            logger.info(f"ğŸ¯ Top result: {disaster_results[0].title} ({disaster_results[0].category})")
        
        # ê²°ê³¼ ì „ì†¡
        await ctx.send(sender, results)
        
    except Exception as e:
        logger.error(f"âŒ Error processing disaster query: {e}")
        
        # ì—ëŸ¬ ì‹œ ë¹ˆ ê²°ê³¼ ì „ì†¡
        error_results = DisasterResults(
            disasters=[],
            total_count=0,
            query=msg.query,
            searched_at=int(datetime.now().timestamp()),
            agent_name="WRLD Relief Disaster Agent (Error)"
        )
        
        await ctx.send(sender, error_results)

@agent.on_message(model=AgentStatus)
async def handle_status_request(ctx: Context, sender: str, msg: AgentStatus):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ìš”ì²­ ì²˜ë¦¬"""
    uptime = datetime.now() - start_time
    uptime_str = f"{uptime.days}d {uptime.seconds//3600}h {(uptime.seconds//60)%60}m"
    
    status = AgentStatus(
        status="online",
        last_search=f"Search count: {search_count}",
        total_searches=search_count,
        uptime=uptime_str
    )
    
    logger.info(f"ğŸ“Š Status request from {sender}")
    await ctx.send(sender, status)

@agent.on_interval(period=300.0)  # 5ë¶„ë§ˆë‹¤
async def periodic_health_check(ctx: Context):
    """ì£¼ê¸°ì  ìƒíƒœ ì²´í¬"""
    logger.info(f"ğŸ’“ Health check - Searches: {search_count}, Uptime: {datetime.now() - start_time}")

# HTTP ìƒíƒœ í™•ì¸ì„ ìœ„í•œ ê°„ë‹¨í•œ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
from fastapi import FastAPI
from fastapi.responses import JSONResponse

# FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (uAgentì™€ ë³„ë„)
status_app = FastAPI(title="WRLD Relief Disaster Agent Status")

@status_app.get("/")
async def agent_status():
    """ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    uptime = datetime.now() - start_time
    return JSONResponse({
        "agent_name": "WRLD Relief Disaster Agent",
        "status": "online",
        "address": str(agent.address),
        "port": 8001,
        "search_count": search_count,
        "uptime": f"{uptime.days}d {uptime.seconds//3600}h {(uptime.seconds//60)%60}m",
        "ai_engine": "initialized" if search_engine else "not_initialized",
        "endpoints": agent._endpoints,
        "message": "Agent is running and ready for disaster monitoring!",
        "protocols": ["DisasterQuery", "DisasterResults", "AgentStatus"],
        "last_health_check": datetime.now().isoformat()
    })

@status_app.get("/health")
async def health_check():
    """ê°„ë‹¨í•œ í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy", "agent": "disaster_monitor", "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    logger.info("ğŸŒ Starting WRLD Relief Disaster Monitoring Agent...")
    logger.info("ğŸ¯ Ready to monitor global disasters and conflicts!")
    logger.info("ğŸ”— Connect via ASI:One or send DisasterQuery messages")
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    agent.run()
